{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shenghaoc/ee5907-ca2/blob/main/lda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I4Ye-nXSvdI0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ipjDKuoK4vXC"
      },
      "outputs": [],
      "source": [
        "# CONSTANTS\n",
        "NUM_SUBJECTS = 68\n",
        "NUM_CHOSEN = 25\n",
        "NUM_IMAGES_PER_SUBJECT = 170\n",
        "\n",
        "TRAIN_RATIO = 0.7\n",
        "NUM_IMAGES = NUM_CHOSEN * NUM_IMAGES_PER_SUBJECT\n",
        "NUM_TRAIN_IMAGES_PER_SUBJECT = np.int_(np.around(TRAIN_RATIO * NUM_IMAGES_PER_SUBJECT))\n",
        "NUM_TRAIN_IMAGES = NUM_CHOSEN * NUM_TRAIN_IMAGES_PER_SUBJECT\n",
        "NUM_TEST_IMAGES = NUM_IMAGES - NUM_TRAIN_IMAGES\n",
        "\n",
        "NUM_SELFIES = 10\n",
        "NUM_TRAIN_SELFIES = np.int_(np.around(TRAIN_RATIO * NUM_SELFIES))\n",
        "NUM_TEST_SELFIES = NUM_SELFIES - NUM_TRAIN_SELFIES\n",
        "SELFIE_LABEL = NUM_SUBJECTS + 1\n",
        "\n",
        "NUM_TOTAL_TRAIN_IMAGES = NUM_TRAIN_IMAGES + NUM_TRAIN_SELFIES\n",
        "NUM_TOTAL_TEST_IMAGES = NUM_TEST_IMAGES + NUM_TEST_SELFIES\n",
        "\n",
        "SEED1 = 2021\n",
        "SEED2 = 2022\n",
        "\n",
        "WIDTH = 32\n",
        "HEIGHT = 32\n",
        "NUM_PIXELS = WIDTH * HEIGHT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Nrq8QHQU5Eo5"
      },
      "outputs": [],
      "source": [
        "# Ensure that the directory to store figures is created\n",
        "figures_directory = Path(\"report\") / \"figures\"\n",
        "figures_directory.mkdir(exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6sY9r2ec5Ga3"
      },
      "outputs": [],
      "source": [
        "# Must start from 1 to accommodate folder naming scheme\n",
        "# Choose NUM_CHOSEN elements from NUM_SUBJECTS integers without replacement\n",
        "chosen = np.random.default_rng(SEED1).choice(\n",
        "    np.arange(1, NUM_SUBJECTS + 1), NUM_CHOSEN, replace=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LJ2E_g7C5IVQ"
      },
      "outputs": [],
      "source": [
        "# Load images from disk\n",
        "# Use lists for manual looping without use of numpy functions\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Assume PIE is in pwd\n",
        "directory = Path(\"PIE\")\n",
        "for i in chosen:\n",
        "    # Do not flatten yet, need to split train and test for each subject\n",
        "    subject_images = []\n",
        "    subject_labels = []\n",
        "    subdirectory = directory / str(i)\n",
        "    # Order is arbitrary for glob, but better to shuffle anyway\n",
        "    files = list(subdirectory.glob(\"*.jpg\"))\n",
        "    np.random.default_rng(SEED2).shuffle(files)\n",
        "    for filename in files:\n",
        "        # PIL is slower but OpenCV is unnecessary\n",
        "        im = Image.open(filename)\n",
        "        subject_images.append(np.array(im))\n",
        "        subject_labels.append(i)  # Use number in PIE for label\n",
        "    images.append(subject_images)\n",
        "    labels.append(subject_labels)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gPyc08oW5KOO"
      },
      "outputs": [],
      "source": [
        "# Slightly altered code for selfies\n",
        "selfie_images = []\n",
        "selfie_labels = []\n",
        "\n",
        "directory = Path(\"resized\")\n",
        "# Assume selfies have been resized and folder is in pwd\n",
        "for filename in directory.glob(\"*.jpg\"):\n",
        "    im = Image.open(filename)\n",
        "    selfie_images.append(np.array(im))\n",
        "    selfie_labels.append(SELFIE_LABEL)  # add 1 to max PIE number to avoid clashes\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "C1U0BPpj5OXe"
      },
      "outputs": [],
      "source": [
        "# Further processing without disk access\n",
        "# Train-test split\n",
        "images_train, images_test = np.split(\n",
        "    np.array(images), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
        ")\n",
        "labels_train, labels_test = np.split(\n",
        "    np.array(labels), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
        ")\n",
        "\n",
        "selfie_images_train, selfie_images_test = np.split(\n",
        "    np.array(selfie_images), [NUM_TRAIN_SELFIES]\n",
        ")\n",
        "selfie_labels_train, selfie_labels_test = np.split(\n",
        "    np.array(selfie_labels), [NUM_TRAIN_SELFIES]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0VdQYE445shw"
      },
      "outputs": [],
      "source": [
        "# Flatterning\n",
        "images_train = images_train.reshape(NUM_TRAIN_IMAGES, NUM_PIXELS)\n",
        "selfie_images_train = selfie_images_train.reshape(NUM_TRAIN_SELFIES, NUM_PIXELS)\n",
        "images_test = images_test.reshape(NUM_TEST_IMAGES, NUM_PIXELS)\n",
        "selfie_images_test = selfie_images_test.reshape(NUM_TEST_SELFIES, NUM_PIXELS)\n",
        "\n",
        "labels_train = labels_train.reshape(NUM_TRAIN_IMAGES)\n",
        "labels_test = labels_test.reshape(NUM_TEST_IMAGES)\n",
        "\n",
        "# Combine PIE images and selfies\n",
        "total_images_train = np.append(\n",
        "    images_train,\n",
        "    selfie_images_train,\n",
        "    axis=0,\n",
        ")\n",
        "total_labels_train = np.append(labels_train, selfie_labels_train)\n",
        "\n",
        "total_images_test = np.append(\n",
        "    images_test,\n",
        "    selfie_images_test,\n",
        "    axis=0,\n",
        ")\n",
        "total_labels_test = np.append(labels_test, selfie_labels_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cOITGOP25_4B"
      },
      "outputs": [],
      "source": [
        "# Start of LDA code\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aHXmi4mfl2Yz"
      },
      "outputs": [],
      "source": [
        "# CONSTANTS\n",
        "LDA_SAMPLE_SIZE = 500\n",
        "# Need to manually adjust this so that at least one selfie is included in the sample\n",
        "SEED3 = 2020\n",
        "MAX_LDA_DIM = 2009"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9VoVW0ldl825"
      },
      "outputs": [],
      "source": [
        "chosen = np.random.default_rng(SEED3).choice(\n",
        "    np.arange(NUM_TOTAL_TRAIN_IMAGES), LDA_SAMPLE_SIZE, replace=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HOnVq3GZmR2i"
      },
      "outputs": [],
      "source": [
        "# According to most sources\n",
        "# rows: n data points (500)\n",
        "# columns: p features (1024)\n",
        "X_train = total_images_train\n",
        "y_train = total_labels_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_vSR6zzVmXg7"
      },
      "outputs": [],
      "source": [
        "# LDA\n",
        "# This is the same random sampled data from PCA, hence labels are repeated and\n",
        "# not in order\n",
        "\n",
        "# Each label also has different number of samples, hindering vectorization due\n",
        "# to numpy's limitation\n",
        "\n",
        "# I use labels instead of classes because class cannot be a variable name in\n",
        "# Python\n",
        "\n",
        "# First, get sorted, unique labels\n",
        "unique_labels = np.unique(y_train)\n",
        "label_feature_means = np.zeros((len(unique_labels),NUM_PIXELS))\n",
        "\n",
        "within_label_scatter_matrix = np.zeros((NUM_PIXELS,NUM_PIXELS))\n",
        "\n",
        "for i in range(len(unique_labels)):\n",
        "  label = unique_labels[i]\n",
        "  label_samples=X_train[y_train==label]\n",
        "  label_feature_means[i]=np.mean(label_samples, axis=0)\n",
        "\n",
        "  s = np.zeros((NUM_PIXELS,NUM_PIXELS))\n",
        "  for label_sample in label_samples:\n",
        "    s += np.outer((label_sample - label_feature_means[i]),(label_sample - label_feature_means[i]))\n",
        "  \n",
        "  within_label_scatter_matrix += s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MbCTEXJatWd8"
      },
      "outputs": [],
      "source": [
        "feature_means = np.mean(X_train, axis=0)\n",
        "\n",
        "between_label_scatter_matrix = np.zeros((NUM_PIXELS,NUM_PIXELS))\n",
        "\n",
        "for i in range(len(unique_labels)):\n",
        "  label = unique_labels[i]\n",
        "  n = np.count_nonzero(y_train==label)\n",
        "  between_label_scatter_matrix += n * np.outer((label_feature_means[i] - feature_means) , (label_feature_means[i] - feature_means))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "F71du4yz0b4s",
        "outputId": "74777d16-a099-4a2b-dcc9-6fc6d4366c56"
      },
      "outputs": [],
      "source": [
        "# Each sample (subject) has only 170 images, compared with 1024 dimensions, likely need to do PCA first?\n",
        "u, s, vh = np.linalg.svd(np.linalg.inv(within_label_scatter_matrix) @ between_label_scatter_matrix, full_matrices=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPpNFop9CJH/xJv+czs9lYd",
      "include_colab_link": true,
      "name": "lda.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "3d696ce10866082c4eb7bd694ea5887227a251ce4d3eddcc2b712d743c9658fc"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('venv': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
