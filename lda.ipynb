{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lda.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpNFop9CJH/xJv+czs9lYd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shenghaoc/ee5907-ca2/blob/main/lda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4Ye-nXSvdI0"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipjDKuoK4vXC"
      },
      "source": [
        "# CONSTANTS\n",
        "NUM_SUBJECTS = 68\n",
        "NUM_CHOSEN = 25\n",
        "NUM_IMAGES_PER_SUBJECT = 170\n",
        "\n",
        "TRAIN_RATIO = 0.7\n",
        "NUM_IMAGES = NUM_CHOSEN * NUM_IMAGES_PER_SUBJECT\n",
        "NUM_TRAIN_IMAGES_PER_SUBJECT = np.int_(np.around(TRAIN_RATIO * NUM_IMAGES_PER_SUBJECT))\n",
        "NUM_TRAIN_IMAGES = NUM_CHOSEN * NUM_TRAIN_IMAGES_PER_SUBJECT\n",
        "NUM_TEST_IMAGES = NUM_IMAGES - NUM_TRAIN_IMAGES\n",
        "\n",
        "NUM_SELFIES = 10\n",
        "NUM_TRAIN_SELFIES = np.int_(np.around(TRAIN_RATIO * NUM_SELFIES))\n",
        "NUM_TEST_SELFIES = NUM_SELFIES - NUM_TRAIN_SELFIES\n",
        "SELFIE_LABEL = NUM_SUBJECTS + 1\n",
        "\n",
        "NUM_TOTAL_TRAIN_IMAGES = NUM_TRAIN_IMAGES + NUM_TRAIN_SELFIES\n",
        "NUM_TOTAL_TEST_IMAGES = NUM_TEST_IMAGES + NUM_TEST_SELFIES\n",
        "\n",
        "SEED1 = 2021\n",
        "SEED2 = 2022\n",
        "\n",
        "WIDTH = 32\n",
        "HEIGHT = 32\n",
        "NUM_PIXELS = WIDTH * HEIGHT\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrq8QHQU5Eo5"
      },
      "source": [
        "# Ensure that the directory to store figures is created\n",
        "figures_directory = Path(\"report\") / \"figures\"\n",
        "figures_directory.mkdir(exist_ok=True)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sY9r2ec5Ga3"
      },
      "source": [
        "# Must start from 1 to accommodate folder naming scheme\n",
        "# Choose NUM_CHOSEN elements from NUM_SUBJECTS integers without replacement\n",
        "chosen = np.random.default_rng(SEED1).choice(\n",
        "    np.arange(1, NUM_SUBJECTS + 1), NUM_CHOSEN, replace=False\n",
        ")\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ2E_g7C5IVQ"
      },
      "source": [
        "# Load images from disk\n",
        "# Use lists for manual looping without use of numpy functions\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Assume PIE is in pwd\n",
        "directory = Path(\"PIE\")\n",
        "for i in chosen:\n",
        "    # Do not flatten yet, need to split train and test for each subject\n",
        "    subject_images = []\n",
        "    subject_labels = []\n",
        "    subdirectory = directory / str(i)\n",
        "    # Order is arbitrary for glob, but better to shuffle anyway\n",
        "    files = list(subdirectory.glob(\"*.jpg\"))\n",
        "    np.random.default_rng(SEED2).shuffle(files)\n",
        "    for filename in files:\n",
        "        # PIL is slower but OpenCV is unnecessary\n",
        "        im = Image.open(filename)\n",
        "        subject_images.append(np.array(im))\n",
        "        subject_labels.append(i)  # Use number in PIE for label\n",
        "    images.append(subject_images)\n",
        "    labels.append(subject_labels)\n",
        "    "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPyc08oW5KOO"
      },
      "source": [
        "# Slightly altered code for selfies\n",
        "selfie_images = []\n",
        "selfie_labels = []\n",
        "\n",
        "directory = Path(\"resized\")\n",
        "# Assume selfies have been resized and folder is in pwd\n",
        "for filename in directory.glob(\"*.jpg\"):\n",
        "    im = Image.open(filename)\n",
        "    selfie_images.append(np.array(im))\n",
        "    selfie_labels.append(SELFIE_LABEL)  # add 1 to max PIE number to avoid clashes\n",
        "    "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1U0BPpj5OXe"
      },
      "source": [
        "# Further processing without disk access\n",
        "# Train-test split\n",
        "images_train, images_test = np.split(\n",
        "    np.array(images), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
        ")\n",
        "labels_train, labels_test = np.split(\n",
        "    np.array(labels), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
        ")\n",
        "\n",
        "selfie_images_train, selfie_images_test = np.split(\n",
        "    np.array(selfie_images), [NUM_TRAIN_SELFIES]\n",
        ")\n",
        "selfie_labels_train, selfie_labels_test = np.split(\n",
        "    np.array(selfie_labels), [NUM_TRAIN_SELFIES]\n",
        ")\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VdQYE445shw"
      },
      "source": [
        "# Flatterning\n",
        "images_train = images_train.reshape(NUM_TRAIN_IMAGES, NUM_PIXELS)\n",
        "selfie_images_train = selfie_images_train.reshape(NUM_TRAIN_SELFIES, NUM_PIXELS)\n",
        "images_test = images_test.reshape(NUM_TEST_IMAGES, NUM_PIXELS)\n",
        "selfie_images_test = selfie_images_test.reshape(NUM_TEST_SELFIES, NUM_PIXELS)\n",
        "\n",
        "labels_train = labels_train.reshape(NUM_TRAIN_IMAGES)\n",
        "labels_test = labels_test.reshape(NUM_TEST_IMAGES)\n",
        "\n",
        "# Combine PIE images and selfies\n",
        "total_images_train = np.append(\n",
        "    images_train,\n",
        "    selfie_images_train,\n",
        "    axis=0,\n",
        ")\n",
        "total_labels_train = np.append(labels_train, selfie_labels_train)\n",
        "\n",
        "total_images_test = np.append(\n",
        "    images_test,\n",
        "    selfie_images_test,\n",
        "    axis=0,\n",
        ")\n",
        "total_labels_test = np.append(labels_test, selfie_labels_test)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOITGOP25_4B"
      },
      "source": [
        "# Start of LDA code\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHXmi4mfl2Yz"
      },
      "source": [
        "# CONSTANTS\n",
        "LDA_SAMPLE_SIZE = 500\n",
        "# Need to manually adjust this so that at least one selfie is included in the sample\n",
        "SEED3 = 2020\n",
        "MAX_LDA_DIM = 2009"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VoVW0ldl825"
      },
      "source": [
        "chosen = np.random.default_rng(SEED3).choice(\n",
        "    np.arange(NUM_TOTAL_TRAIN_IMAGES), LDA_SAMPLE_SIZE, replace=False\n",
        ")"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOnVq3GZmR2i"
      },
      "source": [
        "# According to most sources\n",
        "# rows: n data points (500)\n",
        "# columns: p features (1024)\n",
        "X_train = total_images_train\n",
        "y_train = total_labels_train"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vSR6zzVmXg7"
      },
      "source": [
        "# LDA\n",
        "# This is the same random sampled data from PCA, hence labels are repeated and\n",
        "# not in order\n",
        "\n",
        "# Each label also has different number of samples, hindering vectorization due\n",
        "# to numpy's limitation\n",
        "\n",
        "# I use labels instead of classes because class cannot be a variable name in\n",
        "# Python\n",
        "\n",
        "# First, get sorted, unique labels\n",
        "unique_labels = np.unique(y_train)\n",
        "label_feature_means = np.zeros((len(unique_labels),NUM_PIXELS))\n",
        "\n",
        "within_label_scatter_matrix = np.zeros((NUM_PIXELS,NUM_PIXELS))\n",
        "\n",
        "for i in range(len(unique_labels)):\n",
        "  label = unique_labels[i]\n",
        "  label_samples=X_train[y_train==label]\n",
        "  label_feature_means[i]=np.mean(label_samples, axis=0)\n",
        "\n",
        "  s = np.zeros((NUM_PIXELS,NUM_PIXELS))\n",
        "  for label_sample in label_samples:\n",
        "    s += (label_sample - label_feature_means[i]) @ (label_sample - label_feature_means[i]).T\n",
        "  \n",
        "  within_label_scatter_matrix += s\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbCTEXJatWd8"
      },
      "source": [
        "feature_means = np.mean(X_train, axis=0)\n",
        "\n",
        "between_label_scatter_matrix = np.zeros((NUM_PIXELS,NUM_PIXELS))\n",
        "\n",
        "for i in range(len(unique_labels)):\n",
        "  label = unique_labels[i]\n",
        "  n = np.count_nonzero(y_train==label)\n",
        "\n",
        "  between_label_scatter_matrix += n * (label_feature_means[i] - label_means) @ (label_feature_means[i] - label_means).T"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "F71du4yz0b4s",
        "outputId": "74777d16-a099-4a2b-dcc9-6fc6d4366c56"
      },
      "source": [
        "# Each sample has only 170 subjects, compared with 1024 dimensions, likely need to do PCA first?\n",
        "u, s, vh = np.linalg.svd(np.linalg.inv(within_label_scatter_matrix) @ between_label_scatter_matrix, full_matrices=True)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34172/1126484686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwithin_label_scatter_matrix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mbetween_label_scatter_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m~\\dev\\ee5907-ca2\\venv\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\dev\\ee5907-ca2\\venv\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
          ]
        }
      ]
    }
  ]
}