{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shenghaoc/ee5907-ca2/blob/main/svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "NUM_SUBJECTS = 68\n",
    "NUM_CHOSEN = 25\n",
    "NUM_IMAGES_PER_SUBJECT = 170\n",
    "\n",
    "TRAIN_RATIO = 0.7\n",
    "NUM_IMAGES = NUM_CHOSEN * NUM_IMAGES_PER_SUBJECT\n",
    "NUM_TRAIN_IMAGES_PER_SUBJECT = np.int_(np.around(TRAIN_RATIO * NUM_IMAGES_PER_SUBJECT))\n",
    "NUM_TRAIN_IMAGES = NUM_CHOSEN * NUM_TRAIN_IMAGES_PER_SUBJECT\n",
    "NUM_TEST_IMAGES = NUM_IMAGES - NUM_TRAIN_IMAGES\n",
    "\n",
    "NUM_SELFIES = 10\n",
    "NUM_TRAIN_SELFIES = np.int_(np.around(TRAIN_RATIO * NUM_SELFIES))\n",
    "NUM_TEST_SELFIES = NUM_SELFIES - NUM_TRAIN_SELFIES\n",
    "SELFIE_LABEL = NUM_SUBJECTS + 1\n",
    "\n",
    "NUM_TOTAL_TRAIN_IMAGES = NUM_TRAIN_IMAGES + NUM_TRAIN_SELFIES\n",
    "NUM_TOTAL_TEST_IMAGES = NUM_TEST_IMAGES + NUM_TEST_SELFIES\n",
    "\n",
    "SEED1 = 2021\n",
    "SEED2 = 2022\n",
    "\n",
    "WIDTH = 32\n",
    "HEIGHT = 32\n",
    "NUM_PIXELS = WIDTH * HEIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure that the directory to store figures is created\n",
    "figures_directory = Path(\"report\") / \"figures\"\n",
    "figures_directory.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Must start from 1 to accommodate folder naming scheme\n",
    "# Choose NUM_CHOSEN elements from NUM_SUBJECTS integers without replacement\n",
    "chosen = np.random.default_rng(SEED1).choice(\n",
    "    np.arange(1, NUM_SUBJECTS + 1), NUM_CHOSEN, replace=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load images from disk\n",
    "# Use lists for manual looping without use of numpy functions\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Assume PIE is in pwd\n",
    "directory = Path(\"PIE\")\n",
    "for i in chosen:\n",
    "    # Do not flatten yet, need to split train and test for each subject\n",
    "    subject_images = []\n",
    "    subject_labels = []\n",
    "    subdirectory = directory / str(i)\n",
    "    # Order is arbitrary for glob, but better to shuffle anyway\n",
    "    files = list(subdirectory.glob(\"*.jpg\"))\n",
    "    np.random.default_rng(SEED2).shuffle(files)\n",
    "    for filename in files:\n",
    "        # PIL is slower but OpenCV is unnecessary\n",
    "        im = Image.open(filename)\n",
    "        subject_images.append(np.array(im))\n",
    "        subject_labels.append(i)  # Use number in PIE for label\n",
    "    images.append(subject_images)\n",
    "    labels.append(subject_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Slightly altered code for selfies\n",
    "selfie_images = []\n",
    "selfie_labels = []\n",
    "\n",
    "directory = Path(\"resized\")\n",
    "# Assume selfies have been resized and folder is in pwd\n",
    "for filename in directory.glob(\"*.jpg\"):\n",
    "    im = Image.open(filename)\n",
    "    selfie_images.append(np.array(im))\n",
    "    selfie_labels.append(SELFIE_LABEL)  # add 1 to max PIE number to avoid clashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Further processing without disk access\n",
    "# Train-test split\n",
    "images_train, images_test = np.split(\n",
    "    np.array(images), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
    ")\n",
    "labels_train, labels_test = np.split(\n",
    "    np.array(labels), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
    ")\n",
    "\n",
    "selfie_images_train, selfie_images_test = np.split(\n",
    "    np.array(selfie_images), [NUM_TRAIN_SELFIES]\n",
    ")\n",
    "selfie_labels_train, selfie_labels_test = np.split(\n",
    "    np.array(selfie_labels), [NUM_TRAIN_SELFIES]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Flatterning\n",
    "images_train = images_train.reshape(NUM_TRAIN_IMAGES, NUM_PIXELS)\n",
    "selfie_images_train = selfie_images_train.reshape(NUM_TRAIN_SELFIES, NUM_PIXELS)\n",
    "images_test = images_test.reshape(NUM_TEST_IMAGES, NUM_PIXELS)\n",
    "selfie_images_test = selfie_images_test.reshape(NUM_TEST_SELFIES, NUM_PIXELS)\n",
    "\n",
    "labels_train = labels_train.reshape(NUM_TRAIN_IMAGES)\n",
    "labels_test = labels_test.reshape(NUM_TEST_IMAGES)\n",
    "\n",
    "# Combine PIE images and selfies\n",
    "total_images_train = np.append(\n",
    "    images_train,\n",
    "    selfie_images_train,\n",
    "    axis=0,\n",
    ")\n",
    "total_labels_train = np.append(labels_train, selfie_labels_train)\n",
    "\n",
    "total_images_test = np.append(\n",
    "    images_test,\n",
    "    selfie_images_test,\n",
    "    axis=0,\n",
    ")\n",
    "total_labels_test = np.append(labels_test, selfie_labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start of PCA code\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "PCA_SAMPLE_SIZE = 500\n",
    "# Need to manually adjust this so that at least one selfie is included in the sample\n",
    "SEED3 = 2020\n",
    "MAX_PCA_DIM = NUM_PIXELS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chosen = np.random.default_rng(SEED3).choice(\n",
    "    np.arange(NUM_TOTAL_TRAIN_IMAGES), PCA_SAMPLE_SIZE, replace=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# According to most sources\n",
    "# rows: n data points (500)\n",
    "# columns: p features (1024)\n",
    "X_train = total_images_train\n",
    "y_train = total_labels_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "mean_X = np.mean(X_train, axis=0)\n",
    "centered_X = X_train - mean_X\n",
    "\n",
    "# Use full_matrices=False (\"econ\" option in MATLAB) since we only need 200 dimensions at most\n",
    "# min(500,1024) = 500\n",
    "u, s, vh = np.linalg.svd(centered_X, full_matrices=False)\n",
    "\n",
    "# Unlike MATLAB, s is only the diagonal, hence the need to reconstruct\n",
    "s_matrix = np.diag(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Original matrix: 500 rows of training data points, 1024 columns of features\n",
    "# s_matrix columns correspond to the features, even though extra columns beyond\n",
    "# the number of data points are dropped because they are just zeros\n",
    "# Principal components are the columns of c, with svd guaranteeing order\n",
    "\n",
    "# Calculate once for max dim and then use the columns\n",
    "X_pca = u[:, :MAX_PCA_DIM] @ s_matrix[:MAX_PCA_DIM, :MAX_PCA_DIM]\n",
    "\n",
    "# Do masking (selfie check) once for highlighting selfie later\n",
    "selfie_X_pca = X_pca[y_train == SELFIE_LABEL]\n",
    "pie_X_pca = X_pca[y_train != SELFIE_LABEL]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start of SVM code\n",
    "from libsvm.svm import svm_problem, svm_parameter\n",
    "from libsvm.svmutil import svm_train, svm_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Center test set\n",
    "total_mean_X_test = np.mean(total_images_test, axis=0)\n",
    "total_centered_X_test = total_images_test - total_mean_X_test\n",
    "\n",
    "# Project new face into face space\n",
    "# The columns of vh.T are the eigenfaces\n",
    "# Calculate once for max dim and then use the columns\n",
    "total_X_pca_test = total_centered_X_test @ vh.T[:, :MAX_PCA_DIM]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def do_svm_c(c, prob):\n",
    "    print(\"For penalty parameter C: \" + str(c) + \":\")\n",
    "    # -t kernel_type : set type of kernel function (default 2)\n",
    "    # 0 -- linear: u'*v\n",
    "    # -c cost : set the parameter C of C-SVC, epsilon-SVR, and nu-SVR (default 1)\n",
    "    param = svm_parameter(\"-t 0 -c \" + str(c))\n",
    "    m = svm_train(prob, param)\n",
    "    p_label, p_acc, p_val = svm_predict(total_labels_test, total_X_pca_test, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def do_svm_dim(dim, X, y):\n",
    "    X = X[:, :dim]  # Fix dimensions\n",
    "    prob = svm_problem(y, X)\n",
    "    print(\"For dimensionality \" + str(dim) + \":\")\n",
    "    # Vary C\n",
    "    do_svm_c(1e-2, prob)\n",
    "    do_svm_c(1e-1, prob)\n",
    "    do_svm_c(1, prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dimensionality 1024:\n",
      "For penalty parameter C: 0.01:\n",
      "Accuracy = 98.5133% (1259/1278) (classification)\n",
      "For penalty parameter C: 0.1:\n",
      "Accuracy = 98.5133% (1259/1278) (classification)\n",
      "For penalty parameter C: 1:\n",
      "Accuracy = 98.5133% (1259/1278) (classification)\n"
     ]
    }
   ],
   "source": [
    "do_svm_dim(NUM_PIXELS, X_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dimensionality 200:\n",
      "For penalty parameter C: 0.01:\n",
      "Accuracy = 98.4351% (1258/1278) (classification)\n",
      "For penalty parameter C: 0.1:\n",
      "Accuracy = 98.4351% (1258/1278) (classification)\n",
      "For penalty parameter C: 1:\n",
      "Accuracy = 98.4351% (1258/1278) (classification)\n"
     ]
    }
   ],
   "source": [
    "do_svm_dim(200, X_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dimensionality 80:\n",
      "For penalty parameter C: 0.01:\n",
      "Accuracy = 97.9656% (1252/1278) (classification)\n",
      "For penalty parameter C: 0.1:\n",
      "Accuracy = 97.9656% (1252/1278) (classification)\n",
      "For penalty parameter C: 1:\n",
      "Accuracy = 97.9656% (1252/1278) (classification)\n"
     ]
    }
   ],
   "source": [
    "do_svm_dim(80, X_pca, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110ce578b8677349b8472a66146755bd1a67b699d95d0193dbf21e135c34359f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
