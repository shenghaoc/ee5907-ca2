{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shenghaoc/ee5907-ca2/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "NUM_SUBJECTS = 68\n",
    "NUM_CHOSEN = 25\n",
    "NUM_IMAGES_PER_SUBJECT = 170\n",
    "\n",
    "TRAIN_RATIO = 0.7\n",
    "NUM_IMAGES = NUM_CHOSEN * NUM_IMAGES_PER_SUBJECT\n",
    "NUM_TRAIN_IMAGES_PER_SUBJECT = np.int_(np.around(TRAIN_RATIO * NUM_IMAGES_PER_SUBJECT))\n",
    "NUM_TRAIN_IMAGES = NUM_CHOSEN * NUM_TRAIN_IMAGES_PER_SUBJECT\n",
    "NUM_TEST_IMAGES = NUM_IMAGES - NUM_TRAIN_IMAGES\n",
    "\n",
    "NUM_SELFIES = 10\n",
    "NUM_TRAIN_SELFIES = np.int_(np.around(TRAIN_RATIO * NUM_SELFIES))\n",
    "NUM_TEST_SELFIES = NUM_SELFIES - NUM_TRAIN_SELFIES\n",
    "SELFIE_LABEL = NUM_SUBJECTS + 1\n",
    "\n",
    "NUM_TOTAL_TRAIN_IMAGES = NUM_TRAIN_IMAGES + NUM_TRAIN_SELFIES\n",
    "NUM_TOTAL_TEST_IMAGES = NUM_TEST_IMAGES + NUM_TEST_SELFIES\n",
    "\n",
    "SEED1 = 2021\n",
    "SEED2 = 2022\n",
    "\n",
    "WIDTH = 32\n",
    "HEIGHT = 32\n",
    "NUM_PIXELS = WIDTH * HEIGHT\n",
    "\n",
    "# New constants due to need to fit input for tensorflow\n",
    "NUM_PEOPLE = NUM_CHOSEN + 1  # meaning plus the person with 10 selfies\n",
    "NUM_CHANNELS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure that the directory to store figures is created\n",
    "figures_directory = Path(\"report\") / \"figures\"\n",
    "figures_directory.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Must start from 1 to accommodate folder naming scheme\n",
    "# Choose NUM_CHOSEN elements from NUM_SUBJECTS integers without replacement\n",
    "chosen = np.random.default_rng(SEED1).choice(\n",
    "    np.arange(1, NUM_SUBJECTS + 1), NUM_CHOSEN, replace=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load images from disk\n",
    "# Use lists for manual looping without use of numpy functions\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Assume PIE is in pwd\n",
    "directory = Path(\"PIE\")\n",
    "for i in range(len(chosen)):\n",
    "    # Do not flatten yet, need to split train and test for each subject\n",
    "    subject_images = []\n",
    "    subject_labels = []\n",
    "    subdirectory = directory / str(chosen[i])\n",
    "    # Order is arbitrary for glob, but better to shuffle anyway\n",
    "    files = list(subdirectory.glob(\"*.jpg\"))\n",
    "    np.random.default_rng(SEED2).shuffle(files)\n",
    "    for filename in files:\n",
    "        # PIL is slower but OpenCV is unnecessary\n",
    "        im = Image.open(filename)\n",
    "        subject_images.append(np.array(im))\n",
    "        # For tensorflow input, use sequential label\n",
    "        subject_labels.append(i)\n",
    "    images.append(subject_images)\n",
    "    labels.append(subject_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Slightly altered code for selfies\n",
    "selfie_images = []\n",
    "selfie_labels = []\n",
    "\n",
    "directory = Path(\"resized\")\n",
    "# Assume selfies have been resized and folder is in pwd\n",
    "for filename in directory.glob(\"*.jpg\"):\n",
    "    im = Image.open(filename)\n",
    "    selfie_images.append(np.array(im))\n",
    "    # For tensorflow input, use number of chosen subjects (25) to avoid clashes\n",
    "    selfie_labels.append(NUM_CHOSEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Further processing without disk access\n",
    "# Train-test split\n",
    "images_train, images_test = np.split(\n",
    "    np.array(images), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
    ")\n",
    "labels_train, labels_test = np.split(\n",
    "    np.array(labels), [NUM_TRAIN_IMAGES_PER_SUBJECT], axis=1\n",
    ")\n",
    "\n",
    "selfie_images_train, selfie_images_test = np.split(\n",
    "    np.array(selfie_images), [NUM_TRAIN_SELFIES]\n",
    ")\n",
    "selfie_labels_train, selfie_labels_test = np.split(\n",
    "    np.array(selfie_labels), [NUM_TRAIN_SELFIES]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Flatterning\n",
    "# For Conv2D, a 4+D tensor is required, add 1 for the grayscale channel\n",
    "images_train = images_train.reshape(NUM_TRAIN_IMAGES, WIDTH, HEIGHT, NUM_CHANNELS)\n",
    "selfie_images_train = selfie_images_train.reshape(\n",
    "    NUM_TRAIN_SELFIES, WIDTH, HEIGHT, NUM_CHANNELS\n",
    ")\n",
    "images_test = images_test.reshape(NUM_TEST_IMAGES, WIDTH, HEIGHT, NUM_CHANNELS)\n",
    "selfie_images_test = selfie_images_test.reshape(\n",
    "    NUM_TEST_SELFIES, WIDTH, HEIGHT, NUM_CHANNELS\n",
    ")\n",
    "\n",
    "labels_train = labels_train.reshape(NUM_TRAIN_IMAGES)\n",
    "labels_test = labels_test.reshape(NUM_TEST_IMAGES)\n",
    "\n",
    "# Combine PIE images and selfies\n",
    "total_images_train = np.append(\n",
    "    images_train,\n",
    "    selfie_images_train,\n",
    "    axis=0,\n",
    ")\n",
    "total_labels_train = np.append(labels_train, selfie_labels_train)\n",
    "\n",
    "total_images_test = np.append(\n",
    "    images_test,\n",
    "    selfie_images_test,\n",
    "    axis=0,\n",
    ")\n",
    "total_labels_test = np.append(labels_test, selfie_labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start of CNN code\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "CONV_KERNEL_SIZE = 5\n",
    "MAX_POOL_KERNEL_SIZE = 2\n",
    "MAX_POOL_SIZE = 2\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load numpy arrays\n",
    "# Use built-in one-hot encoder, the numerical labels have no meaning, encoding is necessary to avoid misinterpretation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (total_images_train, tf.keras.utils.to_categorical(total_labels_train))\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (total_images_test, tf.keras.utils.to_categorical(total_labels_test))\n",
    ")\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.cache()\n",
    "    .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "test_dataset = test_dataset.cache().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        # Not really necessary, but good practice?\n",
    "        tf.keras.layers.Rescaling(1.0 / 255, input_shape=(WIDTH, HEIGHT, NUM_CHANNELS)),\n",
    "        tf.keras.layers.Conv2D(20, CONV_KERNEL_SIZE, activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPool2D(\n",
    "            pool_size=(MAX_POOL_KERNEL_SIZE, MAX_POOL_KERNEL_SIZE),\n",
    "            strides=(MAX_POOL_SIZE, MAX_POOL_SIZE),\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(50, CONV_KERNEL_SIZE, activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPool2D(\n",
    "            pool_size=(MAX_POOL_KERNEL_SIZE, MAX_POOL_KERNEL_SIZE),\n",
    "            strides=(MAX_POOL_SIZE, MAX_POOL_SIZE),\n",
    "        ),\n",
    "        tf.keras.layers.Flatten(),  # too many dimensions after Conv2D\n",
    "        tf.keras.layers.Dense(500, activation=\"relu\"),\n",
    "        # Keras documentation: often used for last layer because result can be interpreted as \n",
    "        # a probability distribution \n",
    "        tf.keras.layers.Dense(NUM_PEOPLE, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(amsgrad=True), # newest ADAM\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(), # multi-class labeling\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 20)        520       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 20)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 50)        25050     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 50)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1250)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               625500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                13026     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 664,096\n",
      "Trainable params: 664,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 3s 9ms/step - loss: 3.3117 - accuracy: 0.0124\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2610 - accuracy: 0.0402\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2586 - accuracy: 0.0419\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2584 - accuracy: 0.0513\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2567 - accuracy: 0.0510\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.3041 - accuracy: 0.0543\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2543 - accuracy: 0.0483\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2512 - accuracy: 0.0513\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2501 - accuracy: 0.0158\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2770 - accuracy: 0.0080\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2477 - accuracy: 0.0238\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.3145 - accuracy: 0.0691\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2500 - accuracy: 0.0402\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2491 - accuracy: 0.0402\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2481 - accuracy: 0.0402\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2469 - accuracy: 0.0402\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2458 - accuracy: 0.0402\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2444 - accuracy: 0.0402\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2431 - accuracy: 0.0376\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.3373 - accuracy: 0.0744\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2528 - accuracy: 0.0463\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.2388 - accuracy: 0.0463\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.3691 - accuracy: 0.0748\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 3.2421 - accuracy: 0.0490\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2287 - accuracy: 0.0295\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.2139 - accuracy: 0.0459\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2181 - accuracy: 0.0550\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.1921 - accuracy: 0.0376\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2157 - accuracy: 0.0781\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.3224 - accuracy: 0.0567\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2141 - accuracy: 0.0486\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.2046 - accuracy: 0.0419\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2097 - accuracy: 0.0550\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.2349 - accuracy: 0.0345\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.1143 - accuracy: 0.0567\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 3.2696 - accuracy: 0.0359\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 3.0558 - accuracy: 0.0872\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 3.0275 - accuracy: 0.1103\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.9317 - accuracy: 0.0818\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.8674 - accuracy: 0.1160\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.7274 - accuracy: 0.1643\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.5331 - accuracy: 0.2129\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.7276 - accuracy: 0.1502\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.3139 - accuracy: 0.2180\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2.1457 - accuracy: 0.3176\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2.2455 - accuracy: 0.2532\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 2.0893 - accuracy: 0.3196\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.2025 - accuracy: 0.2891\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.6199 - accuracy: 0.4467\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.4506 - accuracy: 0.5084\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3155 - accuracy: 0.5285\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.0658 - accuracy: 0.6549\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.9541 - accuracy: 0.6653\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.8895 - accuracy: 0.6992\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6849 - accuracy: 0.7988\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.7971\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 0.8675\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8984\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.9051\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2890 - accuracy: 0.9276\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.2393 - accuracy: 0.9413\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.1956 - accuracy: 0.9561\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1666 - accuracy: 0.9658\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9688\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9745\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.9792\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.9812\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9846\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9859\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9866\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9899\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9896\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 0.9916\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9920\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9936\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9953\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9970\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0225 - accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9987\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0181 - accuracy: 0.9997\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9997\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9997\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9997\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9997\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169acc422e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is cumulative!\n",
    "model.fit(train_dataset, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.96000469e-01, 3.23834063e-17, 1.22068917e-14, ...,\n",
       "        2.99125755e-14, 5.60216151e-10, 1.69231473e-09],\n",
       "       [9.91360128e-01, 3.62780282e-18, 5.31080883e-14, ...,\n",
       "        9.33449417e-14, 2.89284063e-09, 2.08377005e-09],\n",
       "       [9.94833827e-01, 8.78540389e-17, 1.07576615e-15, ...,\n",
       "        2.35206819e-13, 9.93924179e-11, 2.26093363e-07],\n",
       "       ...,\n",
       "       [5.43096590e-08, 2.67539354e-14, 6.14998058e-20, ...,\n",
       "        3.69697101e-22, 7.55938803e-19, 3.16684581e-02],\n",
       "       [1.19749124e-15, 1.01459995e-02, 2.46369018e-04, ...,\n",
       "        3.46680103e-15, 1.48096184e-12, 3.43635445e-03],\n",
       "       [7.07404881e-12, 2.19561094e-22, 3.06999298e-25, ...,\n",
       "        8.17932796e-25, 1.69240906e-22, 9.99999166e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14663906395435333, 0.9702660441398621]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "110ce578b8677349b8472a66146755bd1a67b699d95d0193dbf21e135c34359f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
